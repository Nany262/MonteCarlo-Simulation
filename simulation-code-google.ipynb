{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries to use\n",
    "\n",
    "Import of the necessary libraries to execute the current program\n",
    "\n",
    "*Importación de las librerías necesarias para ejecutar el programa actual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps #To API google\n",
    "import pandas as pd #To use csv files\n",
    "import numpy as np #To mathematical functions\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions API\n",
    "\n",
    "Returns indications of several parts for a series of waypoints, indications for various means of transport are available.\n",
    "\n",
    "*Devuelve indicaciones de varias partes para una serie de waypoints, estan disponibles indicaciones para varios medios de transporte.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directions_api (origin, destination):\n",
    "    #Max query 2500 per day \n",
    "    key_direction = 'AIzaSyCOuWn0Ut3cIOqsYvXWkV3WwqMf18EFVWw' #Dani\n",
    "    \n",
    "    gmaps = googlemaps.Client(key_direction)\n",
    "    directions = gmaps.directions(origin,destination,\"driving\") # To car\n",
    "    \n",
    "    # To take the duration an distance for the subpoints on the route\n",
    "    list_duration = []\n",
    "    list_distance = []\n",
    "    list_origin = []\n",
    "    list_destination=[]\n",
    "    steps = directions[0]['legs'][0]['steps']\n",
    "\n",
    "    #Add the values in a list\n",
    "    for sub_steps in steps:\n",
    "        list_origin.append([sub_steps['start_location']['lat'],sub_steps['start_location']['lng']])\n",
    "        list_destination.append([sub_steps['end_location']['lat'],sub_steps['end_location']['lng']])\n",
    "        list_duration.append(sub_steps['duration']['value']) # data in seconds\n",
    "        list_distance.append(sub_steps['distance']['value']) # data in meters\n",
    "        \n",
    "    return list_origin,list_destination,list_distance,list_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elevation API\n",
    "\n",
    "The Google Maps Elevation API provides elevation data for all locations on the Earth's surface, including deep locations on the seabed (which return negative values).\n",
    "\n",
    "*Google Maps Elevation API proporciona datos de elevación para todas las ubicaciones sobre la superficie terrestre, incluidas ubicaciones profundas en el lecho marino (que devuelven valores negativos).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation_api(origin, destination): #2 lists with latitude and longitude\n",
    "    #Max query 2500 per day \n",
    "    key_elevation='AIzaSyCOuWn0Ut3cIOqsYvXWkV3WwqMf18EFVWw' #Dani\n",
    "    \n",
    "    gelevation = googlemaps.Client(key_elevation)\n",
    "    elevation = gelevation.elevation([origin, destination])\n",
    "    return elevation[0]['elevation'],elevation[1]['elevation']\n",
    "\n",
    "def geodesic_distance(origin,destination): #2 lists with latitude and longitude\n",
    "    # https://web.archive.org/web/20090813162802/http://gorny.edu.pl/haversine.py\n",
    "    earth_radius = 6371e3\n",
    "    phi1 = origin[0] * np.pi / 180 # Convert to radians lat origin\n",
    "    phi2 = destination[0] * np.pi / 180 # Convert to radians lat destiny\n",
    "    lambda1 = origin[1] * np.pi / 180 # Convert to radians long origin\n",
    "    lambda2 = destination[1] * np.pi / 180 # Convert to radians long origin\n",
    "    \n",
    "    delta_phi = phi2 - phi1\n",
    "    delta_lambda = lambda2 - lambda1\n",
    "    \n",
    "    value_sqrt = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    harvesine = 2 * earth_radius * np.arctan2(np.sqrt(value_sqrt), np.sqrt(1 - value_sqrt))\n",
    "    return harvesine\n",
    "    \n",
    "def get_list_elevation_angle(list_origin, list_destination): \n",
    "    #Return the elevation angle between two points in a list\n",
    "    list_elevation = []\n",
    "    for i in range(len(list_origin)):\n",
    "        elevation_points = elevation_api(list_origin[i], list_destination[i])\n",
    "        distance = geodesic_distance(list_origin[i], list_destination[i])\n",
    "        difference_elevation = elevation_points[1] - elevation_points[0]   \n",
    "        list_elevation.append(np.arctan(np.abs(difference_elevation / distance)) * 180 / np.pi)\n",
    "    return list_elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from model\n",
    "\n",
    "Generation of information necessary to use in the loading and unloading model of the electric vehicle, by restrictions of the API's you can not iterate over all the data at the same time\n",
    "\n",
    "*Generacion de información necesaria para utilizar en el modelo de carga y descarga del vehiculo electrico, por restricciones de las API's no se puede iterar sobre todos los datos al tiempo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_from_model():\n",
    "    #File path where the points are located\n",
    "    substations = ['Centro', 'Dosquebradas', 'Ventorrillo', 'Cuba', 'Naranjito']\n",
    "    days = ['Lunes', 'Martes', 'Miercoles', 'Jueves', 'Viernes']\n",
    "    hours = ['6-9', '12-14', '18-20']\n",
    "\n",
    "    for substation in substations:\n",
    "        for day in days:\n",
    "            for hour in hours:\n",
    "                for i in range (1,5):\n",
    "                    print substation,day,hour, 'From V' + str(substations.index(substation)+1) + ' to V'+ str(i) +'_'+ hour+'.csv'\n",
    "                    file_path = 'Substations/' + substation + '/Puntos Aleatorios/'+ day + ' '+ hour +'/From V' + str(substations.index(substation)+1) + ' to V'+ str(i) +'_'+ hour +'.csv'\n",
    "                    data = pd.read_csv(file_path, header=0)\n",
    "                    data_routes= pd.DataFrame()\n",
    "                    columns = ['X1','Y1','X2','Y2','Subpoints_origin','Subpoints_destiny','Distance','Duration','Elevation']\n",
    "                    try:\n",
    "                        for row in data.itertuples():\n",
    "                            route_data_list = directions_api([row[2],row[1]],[row[4],row[3]])\n",
    "                            elevation_data_list = get_list_elevation_angle(route_data_list[0],route_data_list[1])\n",
    "                            x1 = [None]*len(elevation_data_list)\n",
    "                            y1 = [None]*len(elevation_data_list)\n",
    "                            x2 = [None]*len(elevation_data_list)\n",
    "                            y2 = [None]*len(elevation_data_list)\n",
    "\n",
    "                            x1[0] = row[2]\n",
    "                            y1[0] = row[1]\n",
    "                            x2[0] = row[4]\n",
    "                            y2[0] = row[3]\n",
    "                            data_temp = pd.DataFrame({\n",
    "                                'X1':x1,\n",
    "                                'Y1':y1,\n",
    "                                'X2':x2,\n",
    "                                'Y2':y2,\n",
    "                                'Subpoints_origin':route_data_list[0], \n",
    "                                'Subpoints_destiny':route_data_list[1], \n",
    "                                'Distance':route_data_list[2], \n",
    "                                'Duration':route_data_list[3], \n",
    "                                'Elevation':elevation_data_list\n",
    "                            })\n",
    "                            data_routes = pd.concat([data_routes, data_temp], ignore_index=True,keys = [[row[2],row[1]],[row[4],row[3]]])\n",
    "                        data_routes = data_routes[columns] # To order the columns in dataframe\n",
    "                        data_routes.to_csv(file_path, header=columns, index=False)\n",
    "                    except:\n",
    "                        data_routes = data_routes[columns] # To order the columns in dataframe\n",
    "                        data_routes.to_csv('Substations/Centro/Puntos Aleatorios/Lunes 6-9/temp.csv', header=columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic model \n",
    "\n",
    "Model to find out the energy levels used by EV's, this model is presented by David Wen Zhong Gao in his article \"Modeling and Simulation of Electric and Hybrid Vehicles\" wich is based on Newton's second law\n",
    "\n",
    "*Modelo para conocer los niveles de energía utilizados por los VE's, este modelo es presentado por David Wenzhong Gao en su artículo \"Modelado y simulación de vehículos eléctricos e híbridos\" que esta basado en la segunda ley de Newton*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dinamic_model(vehicle_mass, ad_coefficient, frontal_area, wheel_radius, data_route):\n",
    "    #Constants of the model\n",
    "    gravity = 9.8 #m/s\n",
    "    air_density = 1.225 #kg/m^3\n",
    "    rr_coefficient = 0.012 #rolling resistance coefficient (R16) posiblemente\n",
    "    \n",
    "    #Sub-point velocities and aceleration\n",
    "    speeds = np.divide(data_route['Distance'],data_route['Duration'])\n",
    "    aceleration = np.divide(speeds,data_route['Duration'])\n",
    "    \n",
    "    #Gravitational force\n",
    "    fgx = vehicle_mass * gravity * np.sin(data_route['Elevation']) #(kg/s^2)\n",
    "    \n",
    "    #Rolling resistance force\n",
    "    froll= rr_coefficient * vehicle_mass * np.cos(data_route['Elevation'])\n",
    "    \n",
    "    #Strength of aerodynamic resistance\n",
    "    fad = (1/2) * air_density * ad_coefficient * frontal_area * np.power(speeds,2)\n",
    "    \n",
    "    #m*a\n",
    "    ma = (vehicle_mass + (jwh /np.power(wheel_radius,2)) * aceleration)\n",
    "    \n",
    "    #Vehicle force\n",
    "    fd = fgx + froll + fad + ma\n",
    "    \n",
    "    #Power\n",
    "    p = np.multiply(fd*speeds)\n",
    "    \n",
    "    #Energy\n",
    "    e = integrate.cumtrapz(p, data_route['Duration'])\n",
    "    total_e = e.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of montecarlo\n",
    "\n",
    "Main function to execute the execution of the simulation of Montecarlo with the data of the routes for the generated model.The \"Data from model\" section must be executed before performing the simulation since the data of the routes is obtained from it\n",
    "\n",
    "*Función principal para realizar la ejecución de la simulación de montecarlo con los datos de las rutas para el modelo generado. La sección \"Data from model\" debe ser ejecutada antes de realizar la simulación ya que de esta se obtienen los datos de las rutas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "vehicles = {'type_1':[12,12,32],'type_2':[43,23,55],'type_3':[32,54,21]}\n",
    "\n",
    "'''\n",
    "    for substation in substations:\n",
    "        for day in days:\n",
    "            for hour in hours:\n",
    "                for i in range (1,5):\n",
    "                    print substation,day,hour, 'From V' + str(substations.index(substation)+1) + ' to V'+ str(i) +'_'+ hour+'.csv'\n",
    "                    file_path = 'Substations/' + substation + '/Puntos Aleatorios/'+ day + ' '+ hour +'/From V' + str(substations.index(substation)+1) + ' to V'+ str(i) +'_'+ hour +'.csv'\n",
    "                    data = pd.read_csv(file_path, header=0)\n",
    "'''\n",
    "file_path = 'Substations/Ventorrillo/Puntos Aleatorios/Lunes 6-9/From V3 to V5_6-9.csv'\n",
    "data_routes = pd.read_csv(file_path, header=0)\n",
    "index_route = []\n",
    "\n",
    "print rand.choice(vehicles.keys())\n",
    "\n",
    "#The routes are identified and add in a list\n",
    "for route in data_routes[data_routes['X1'] > 0].itertuples():\n",
    "     index_route.append(route[0])\n",
    "index_route.append(len(data_routes))\n",
    "\n",
    "#Send the data to the model\n",
    "list_energy = []\n",
    "for i in range(len(index_route)-1):\n",
    "    data = data_routes[(data_routes.index >= index_route[i]) & (data_routes.index < index_route[i+1])]\n",
    "    print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
